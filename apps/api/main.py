from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from pydantic import BaseModel
from typing import List, Optional, Dict, Any
import os
import json
import sqlite3
from pathlib import Path
import uvicorn
import asyncio
import logging

# –ò–º–ø–æ—Ä—Ç AI —Å–µ—Ä–≤–∏—Å–æ–≤
from ai_services import (
    initialize_ai_services, 
    get_ai_manager, 
    CodeContext, 
    AIResponse,
    AIServiceError
)

# –ú–æ–¥–µ–ª–∏ –¥–∞–Ω–Ω—ã—Ö
class ProjectAnalysisRequest(BaseModel):
    path: str
    include_tests: bool = True
    analysis_depth: str = "medium"

class FileInfo(BaseModel):
    path: str
    name: str
    type: str
    size: int
    lines_of_code: Optional[int] = None
    functions: List[str] = []
    imports: List[str] = []

class ProjectAnalysisResult(BaseModel):
    project_path: str
    files: List[FileInfo]
    dependencies: List[Dict[str, Any]]
    metrics: Dict[str, Any]
    architecture_patterns: List[str]

class CodeExplanationRequest(BaseModel):
    code: str
    language: str = "javascript"
    level: str = "intermediate"
    file_path: Optional[str] = None
    project_context: Optional[Dict[str, Any]] = None

class CodeExplanation(BaseModel):
    explanation: str
    concepts: List[str]
    examples: List[str]
    recommendations: List[str]
    improvements: List[str] = []
    patterns: List[str] = []
    confidence_score: float = 0.0
    ai_provider: str = "unknown"

class ComprehensiveAnalysisRequest(BaseModel):
    file_path: str
    project_path: str
    explanation_level: str = "intermediate"

class ComprehensiveAnalysisResult(BaseModel):
    explanation: Optional[Dict[str, Any]] = None
    improvements: List[str] = []
    patterns: List[str] = []
    analysis_metadata: Dict[str, Any] = {}

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è –¥–ª—è AI –º–µ–Ω–µ–¥–∂–µ—Ä–∞
ai_manager = None

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è FastAPI
app = FastAPI(
    title="MCP Code Analyzer API with AI Integration",
    description="Backend API for intelligent code analysis and visualization with AI-powered explanations",
    version="0.2.0",
    docs_url="/docs",
    redoc_url="/redoc"
)

# CORS –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
app.add_middleware(
    CORSMiddleware,
    allow_origins=["http://localhost:3000", "http://127.0.0.1:3000", "http://localhost:3002", "http://127.0.0.1:3002"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
def init_database():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è SQLite –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    conn = sqlite3.connect("code_analyzer.db")
    cursor = conn.cursor()
    
    # –¢–∞–±–ª–∏—Ü–∞ –ø—Ä–æ–µ–∫—Ç–æ–≤
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS projects (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            name TEXT NOT NULL,
            path TEXT NOT NULL UNIQUE,
            language TEXT,
            framework TEXT,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """)
    
    # –¢–∞–±–ª–∏—Ü–∞ –∞–Ω–∞–ª–∏–∑–æ–≤
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS analyses (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            project_id INTEGER,
            analysis_type TEXT NOT NULL,
            results TEXT, -- JSON
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
            FOREIGN KEY (project_id) REFERENCES projects (id)
        )
    """)
    
    # –¢–∞–±–ª–∏—Ü–∞ –æ–±—É—á–∞—é—â–∏—Ö —Å–µ—Å—Å–∏–π
    cursor.execute("""
        CREATE TABLE IF NOT EXISTS learning_sessions (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id TEXT,
            topic TEXT,
            progress TEXT, -- JSON
            completed_at TIMESTAMP,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    """)
    
    conn.commit()
    conn.close()

# –£—Ç–∏–ª–∏—Ç—ã –¥–ª—è –∞–Ω–∞–ª–∏–∑–∞ –∫–æ–¥–∞
class CodeAnalyzer:
    @staticmethod
    def analyze_file(file_path: str) -> FileInfo:
        """–ê–Ω–∞–ª–∏–∑ –æ–¥–Ω–æ–≥–æ —Ñ–∞–π–ª–∞"""
        path_obj = Path(file_path)
        
        if not path_obj.exists():
            raise HTTPException(status_code=404, detail="File not found")
        
        file_info = FileInfo(
            path=str(path_obj),
            name=path_obj.name,
            type=path_obj.suffix[1:] if path_obj.suffix else "unknown",
            size=path_obj.stat().st_size,
            lines_of_code=0,
            functions=[],
            imports=[]
        )
        
        # –ê–Ω–∞–ª–∏–∑ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ –¥–ª—è JS/TS/Python —Ñ–∞–π–ª–æ–≤
        if path_obj.suffix in ['.js', '.ts', '.tsx', '.jsx', '.py']:
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    file_info.lines_of_code = len(content.split('\n'))
                    
                    # –ü—Ä–æ—Å—Ç–æ–π –ø–æ–∏—Å–∫ —Ñ—É–Ω–∫—Ü–∏–π (–º–æ–∂–Ω–æ —É–ª—É—á—à–∏—Ç—å)
                    if path_obj.suffix in ['.js', '.ts', '.tsx', '.jsx']:
                        # JavaScript/TypeScript —Ñ—É–Ω–∫—Ü–∏–∏
                        import re
                        functions = re.findall(r'function\s+(\w+)|const\s+(\w+)\s*=.*?=>|(\w+)\s*:\s*\([^)]*\)\s*=>', content)
                        file_info.functions = [f for func_group in functions for f in func_group if f]
                        
                        # –ò–º–ø–æ—Ä—Ç—ã
                        imports = re.findall(r'import.*?from\s+[\'"]([^\'"]+)[\'"]', content)
                        file_info.imports = imports
                    
                    elif path_obj.suffix == '.py':
                        # Python —Ñ—É–Ω–∫—Ü–∏–∏
                        import re
                        functions = re.findall(r'def\s+(\w+)', content)
                        file_info.functions = functions
                        
                        # –ò–º–ø–æ—Ä—Ç—ã
                        imports = re.findall(r'from\s+(\S+)\s+import|import\s+(\S+)', content)
                        file_info.imports = [imp for imp_group in imports for imp in imp_group if imp]
                        
            except Exception as e:
                print(f"Error analyzing file {file_path}: {e}")
        
        return file_info
    
    @staticmethod
    def analyze_project(project_path: str) -> ProjectAnalysisResult:
        """–ê–Ω–∞–ª–∏–∑ –≤—Å–µ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞"""
        path_obj = Path(project_path)
        
        if not path_obj.exists():
            raise HTTPException(status_code=404, detail="Project path not found")
        
        files = []
        dependencies = []
        
        # –°–∫–∞–Ω–∏—Ä—É–µ–º —Ñ–∞–π–ª—ã –ø—Ä–æ–µ–∫—Ç–∞
        for file_path in path_obj.rglob("*"):
            if file_path.is_file() and file_path.suffix in ['.js', '.ts', '.tsx', '.jsx', '.py', '.html', '.css']:
                # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º node_modules –∏ –¥—Ä—É–≥–∏–µ —Å–ª—É–∂–µ–±–Ω—ã–µ –ø–∞–ø–∫–∏
                if any(part in str(file_path) for part in ['node_modules', '.git', 'dist', 'build', '__pycache__']):
                    continue
                
                try:
                    file_info = CodeAnalyzer.analyze_file(str(file_path))
                    files.append(file_info)
                except Exception as e:
                    print(f"Error analyzing {file_path}: {e}")
        
        # –°—Ç—Ä–æ–∏–º –≥—Ä–∞—Ñ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π
        for file_info in files:
            for import_path in file_info.imports:
                dependencies.append({
                    "from": file_info.path,
                    "to": import_path,
                    "type": "import"
                })
        
        # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        total_lines = sum(f.lines_of_code or 0 for f in files)
        total_functions = sum(len(f.functions) for f in files)
        
        metrics = {
            "total_files": len(files),
            "total_lines": total_lines,
            "total_functions": total_functions,
            "avg_lines_per_file": total_lines / len(files) if files else 0,
            "languages": list(set(f.type for f in files if f.type != "unknown"))
        }
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã (—É–ø—Ä–æ—â–µ–Ω–Ω–æ)
        patterns = []
        if any("component" in f.path.lower() for f in files):
            patterns.append("Component Architecture")
        if any("api" in f.path.lower() or "service" in f.path.lower() for f in files):
            patterns.append("Service Layer")
        if any("test" in f.path.lower() for f in files):
            patterns.append("Test Coverage")
        
        return ProjectAnalysisResult(
            project_path=project_path,
            files=files,
            dependencies=dependencies,
            metrics=metrics,
            architecture_patterns=patterns
        )

# API Endpoints
@app.get("/")
async def root():
    """–ì–ª–∞–≤–Ω–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ API"""
    return {
        "message": "MCP Code Analyzer API",
        "version": "0.1.0",
        "status": "running",
        "endpoints": {
            "docs": "/docs",
            "analyze": "/api/analyze",
            "explain": "/api/explain",
            "projects": "/api/projects"
        }
    }

@app.post("/api/analyze", response_model=ProjectAnalysisResult)
async def analyze_project(request: ProjectAnalysisRequest):
    """–ê–Ω–∞–ª–∏–∑ –ø—Ä–æ–µ–∫—Ç–∞"""
    try:
        result = CodeAnalyzer.analyze_project(request.path)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ –±–∞–∑—É
        conn = sqlite3.connect("code_analyzer.db")
        cursor = conn.cursor()
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–µ–∫—Ç
        cursor.execute("""
            INSERT OR REPLACE INTO projects (name, path, language)
            VALUES (?, ?, ?)
        """, (
            os.path.basename(request.path),
            request.path,
            result.metrics.get("languages", ["unknown"])[0] if result.metrics.get("languages") else "unknown"
        ))
        
        project_id = cursor.lastrowid
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∞–Ω–∞–ª–∏–∑
        cursor.execute("""
            INSERT INTO analyses (project_id, analysis_type, results)
            VALUES (?, ?, ?)
        """, (project_id, "full_analysis", json.dumps(result.dict())))
        
        conn.commit()
        conn.close()
        
        return result
        
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/api/explain", response_model=CodeExplanation)
async def explain_code(request: CodeExplanationRequest):
    """
    –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –∫–æ–¥–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º AI.
    –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç OpenAI GPT –∏ Anthropic Claude –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏–π.
    """
    global ai_manager
    
    try:
        # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –∫–æ–¥–∞ –¥–ª—è AI –∞–Ω–∞–ª–∏–∑–∞
        context = CodeContext(
            file_path=request.file_path or "unknown",
            file_content=request.code,
            file_type=request.language,
            project_info=request.project_context or {},
            dependencies=[],
            functions=[],
            imports=[],
            architecture_patterns=[],
            lines_of_code=len(request.code.split('\n'))
        )
        
        # –ï—Å–ª–∏ AI –º–µ–Ω–µ–¥–∂–µ—Ä –¥–æ—Å—Ç—É–ø–µ–Ω, –∏—Å–ø–æ–ª—å–∑—É–µ–º –µ–≥–æ
        if ai_manager and ai_manager.services:
            try:
                # –ü–æ–ª—É—á–∞–µ–º —É–º–Ω–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –æ—Ç AI
                ai_response = await ai_manager.explain_code_smart(context, request.level)
                
                if ai_response:
                    # –¢–∞–∫–∂–µ –ø–æ–ª—É—á–∞–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –∏ –ø–∞—Ç—Ç–µ—Ä–Ω—ã
                    improvements_task = ai_manager.suggest_improvements_smart(context)
                    patterns_task = ai_manager.detect_patterns_smart(context)
                    
                    improvements, patterns = await asyncio.gather(
                        improvements_task, patterns_task, return_exceptions=True
                    )
                    
                    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (–∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏)
                    improvements = improvements if not isinstance(improvements, Exception) else []
                    patterns = patterns if not isinstance(patterns, Exception) else []
                    
                    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–π –ø—Ä–æ–≤–∞–π–¥–µ—Ä
                    used_provider = "unknown"
                    for provider, service in ai_manager.services.items():
                        if service.request_count > 0:
                            used_provider = provider.value
                            break
                    
                    return CodeExplanation(
                        explanation=ai_response.explanation,
                        concepts=ai_response.concepts,
                        examples=ai_response.examples,
                        recommendations=ai_response.recommendations,
                        improvements=improvements[:5],  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
                        patterns=patterns[:5],
                        confidence_score=ai_response.confidence_score,
                        ai_provider=used_provider
                    )
                    
            except AIServiceError as e:
                logger.warning(f"AI —Å–µ—Ä–≤–∏—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: {str(e)}. –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback.")
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ AI –∞–Ω–∞–ª–∏–∑–∞: {str(e)}. –ò—Å–ø–æ–ª—å–∑—É–µ–º fallback.")
        
        # Fallback: –ø—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ –±–µ–∑ AI
        logger.info("–ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è fallback –∞–Ω–∞–ª–∏–∑ –±–µ–∑ AI")
        explanation = f"–≠—Ç–æ—Ç {request.language} –∫–æ–¥ –≤—ã–ø–æ–ª–Ω—è–µ—Ç —Å–ª–µ–¥—É—é—â–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏..."
        
        # –ü—Ä–æ—Å—Ç–æ–π –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ü–µ–ø—Ü–∏–π
        concepts = []
        if "function" in request.code:
            concepts.append("functions")
        if any(keyword in request.code for keyword in ["const", "let", "var"]):
            concepts.append("variables")
        if "import" in request.code:
            concepts.append("modules")
        if "class" in request.code:
            concepts.append("classes")
        if "async" in request.code or "await" in request.code:
            concepts.append("asynchronous programming")
        
        return CodeExplanation(
            explanation=explanation,
            concepts=concepts,
            examples=["–ü—Ä–∏–º–µ—Ä 1: –±–∞–∑–æ–≤–æ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ", "–ü—Ä–∏–º–µ—Ä 2: —Ä–∞—Å—à–∏—Ä–µ–Ω–Ω—ã–π —Å–ª—É—á–∞–π"],
            recommendations=["–î–æ–±–∞–≤—å—Ç–µ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏", "–ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –æ–ø–∏—Å–∞—Ç–µ–ª—å–Ω—ã–µ –∏–º–µ–Ω–∞ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö"],
            improvements=[],
            patterns=[],
            confidence_score=0.5,
            ai_provider="fallback"
        )
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—ä—è—Å–Ω–µ–Ω–∏–∏ –∫–æ–¥–∞: {str(e)}")
        raise HTTPException(status_code=500, detail=f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –∫–æ–¥–∞: {str(e)}")

@app.post("/api/comprehensive-analysis", response_model=ComprehensiveAnalysisResult)
async def comprehensive_analysis(request: ComprehensiveAnalysisRequest):
    """
    –ö–æ–º–ø–ª–µ–∫—Å–Ω—ã–π AI-–∞–Ω–∞–ª–∏–∑ —Ñ–∞–π–ª–∞ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º –≤—Å–µ—Ö –¥–æ—Å—Ç—É–ø–Ω—ã—Ö AI —Å–µ—Ä–≤–∏—Å–æ–≤.
    –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è–µ—Ç –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ, —É–ª—É—á—à–µ–Ω–∏—è –∏ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤.
    """
    global ai_manager
    
    try:
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏–µ —Ñ–∞–π–ª–∞
        if not Path(request.file_path).exists():
            raise HTTPException(status_code=404, detail="–§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ñ–∞–π–ª
        file_info = CodeAnalyzer.analyze_file(request.file_path)
        
        # –ß–∏—Ç–∞–µ–º —Å–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–∞
        with open(request.file_path, 'r', encoding='utf-8') as f:
            file_content = f.read()
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º –ø—Ä–æ–µ–∫—Ç –¥–ª—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        try:
            project_analysis = CodeAnalyzer.analyze_project(request.project_path)
            project_context = {
                "total_files": project_analysis.metrics["total_files"],
                "total_lines": project_analysis.metrics["total_lines"],
                "languages": project_analysis.metrics["languages"],
                "architecture_patterns": project_analysis.architecture_patterns
            }
        except Exception:
            project_context = {}
        
        # –°–æ–∑–¥–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è AI
        context = CodeContext(
            file_path=request.file_path,
            file_content=file_content,
            file_type=file_info.type,
            project_info=project_context,
            dependencies=[],
            functions=file_info.functions,
            imports=file_info.imports,
            architecture_patterns=project_context.get("architecture_patterns", []),
            lines_of_code=file_info.lines_of_code or 0
        )
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –∞–Ω–∞–ª–∏–∑
        if ai_manager and ai_manager.services:
            try:
                results = await ai_manager.comprehensive_analysis(context, request.explanation_level)
                
                # –§–æ—Ä–º–∞—Ç–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
                explanation_data = None
                if results.get("explanation"):
                    explanation_data = {
                        "text": results["explanation"].explanation,
                        "concepts": results["explanation"].concepts,
                        "recommendations": results["explanation"].recommendations,
                        "confidence": results["explanation"].confidence_score
                    }
                
                return ComprehensiveAnalysisResult(
                    explanation=explanation_data,
                    improvements=results.get("improvements", []),
                    patterns=results.get("patterns", []),
                    analysis_metadata=results.get("analysis_metadata", {})
                )
                
            except Exception as e:
                logger.error(f"–û—à–∏–±–∫–∞ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ AI –∞–Ω–∞–ª–∏–∑–∞: {str(e)}")
        
        # Fallback –∞–Ω–∞–ª–∏–∑
        return ComprehensiveAnalysisResult(
            explanation={
                "text": f"–§–∞–π–ª {Path(request.file_path).name} —Å–æ–¥–µ—Ä–∂–∏—Ç {len(file_info.functions)} —Ñ—É–Ω–∫—Ü–∏–π –∏ {file_info.lines_of_code} —Å—Ç—Ä–æ–∫ –∫–æ–¥–∞.",
                "concepts": ["file analysis", "code structure"],
                "recommendations": ["AI –∞–Ω–∞–ª–∏–∑ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"],
                "confidence": 0.3
            },
            improvements=["AI —Å–µ—Ä–≤–∏—Å—ã –Ω–µ–¥–æ—Å—Ç—É–ø–Ω—ã –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞"],
            patterns=["–ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –ø–∞—Ç—Ç–µ—Ä–Ω–æ–≤ –Ω–µ–¥–æ—Å—Ç—É–ø–Ω–æ"],
            analysis_metadata={
                "timestamp": "fallback",
                "ai_available": False
            }
        )
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –∫–æ–º–ø–ª–µ–∫—Å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/api/ai-status")
async def get_ai_status():
    """
    –ü–æ–ª—É—á–µ–Ω–∏–µ —Å—Ç–∞—Ç—É—Å–∞ AI —Å–µ—Ä–≤–∏—Å–æ–≤ –∏ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è.
    """
    global ai_manager
    
    if not ai_manager:
        return {
            "status": "not_initialized",
            "available_services": [],
            "usage_stats": {}
        }
    
    available_services = []
    for provider in ai_manager.services.keys():
        available_services.append(provider.value)
    
    usage_stats = ai_manager.get_all_usage_stats()
    
    return {
        "status": "initialized" if available_services else "no_services",
        "available_services": available_services,
        "usage_stats": usage_stats,
        "total_requests": sum(stats.get("request_count", 0) for stats in usage_stats.values()),
        "total_tokens": sum(stats.get("total_tokens_used", 0) for stats in usage_stats.values())
    }

@app.get("/api/projects")
async def get_projects():
    """–ü–æ–ª—É—á–µ–Ω–∏–µ —Å–ø–∏—Å–∫–∞ –ø—Ä–æ–µ–∫—Ç–æ–≤"""
    conn = sqlite3.connect("code_analyzer.db")
    cursor = conn.cursor()
    
    cursor.execute("""
        SELECT id, name, path, language, created_at, updated_at
        FROM projects
        ORDER BY updated_at DESC
    """)
    
    projects = []
    for row in cursor.fetchall():
        projects.append({
            "id": row[0],
            "name": row[1],
            "path": row[2],
            "language": row[3],
            "created_at": row[4],
            "updated_at": row[5]
        })
    
    conn.close()
    return {"projects": projects}

@app.get("/api/health")
async def health_check():
    """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∑–¥–æ—Ä–æ–≤—å—è API"""
    return {"status": "healthy", "timestamp": "2024-01-01T00:00:00Z"}

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø—Ä–∏ –∑–∞–ø—É—Å–∫–µ
@app.on_event("startup")
async def startup_event():
    global ai_manager
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö
    init_database()
    
    # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è AI —Å–µ—Ä–≤–∏—Å–æ–≤
    try:
        ai_manager = initialize_ai_services()
        if ai_manager.services:
            logger.info(f"ü§ñ AI —Å–µ—Ä–≤–∏—Å—ã –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω—ã: {list(ai_manager.services.keys())}")
        else:
            logger.warning("‚ö†Ô∏è AI —Å–µ—Ä–≤–∏—Å—ã –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω—ã. –£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ OPENAI_API_KEY –∏–ª–∏ ANTHROPIC_API_KEY –≤ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã—Ö –æ–∫—Ä—É–∂–µ–Ω–∏—è.")
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ AI —Å–µ—Ä–≤–∏—Å–æ–≤: {str(e)}")
        ai_manager = None
    
    print("üöÄ MCP Code Analyzer API —Å AI –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–µ–π –∑–∞–ø—É—â–µ–Ω!")
    print("üìñ –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è: http://localhost:8000/docs")
    print("ü§ñ AI —Å—Ç–∞—Ç—É—Å: http://localhost:8000/api/ai-status")

if __name__ == "__main__":
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )
