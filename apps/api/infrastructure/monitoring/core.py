# üöÄ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ –∏ –∞–Ω–∞–ª–∏—Ç–∏–∫–∏
# –§–∞–π–ª: infrastructure/monitoring/core.py

"""
–ú–æ–¥—É–ª—å–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Å –ø—Ä–æ–¥–≤–∏–Ω—É—Ç–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π.

–ö–ª—é—á–µ–≤—ã–µ —É–ª—É—á—à–µ–Ω–∏—è:
1. –ö–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ–º—ã–µ —É—Ä–æ–≤–Ω–∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
2. –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç—å—é  
3. –ú–æ–¥—É–ª—å–Ω–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ —Å –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å—é —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è
4. –ë–∞—Ç—á–∏–Ω–≥ —Å–æ–±—ã—Ç–∏–π –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
5. –ú–µ—Ç—Ä–∏–∫–∏ —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Ä–æ—Ç–∞—Ü–∏–µ–π
6. –ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—Ç–µ—Ä—ã –∏ —ç–∫—Å–ø–æ—Ä—Ç–µ—Ä—ã
"""

import asyncio
import json
import time
import logging
from abc import ABC, abstractmethod
from collections import deque, defaultdict
from contextlib import asynccontextmanager
from dataclasses import dataclass, asdict, field
from datetime import datetime, timezone, timedelta
from enum import Enum, auto
from pathlib import Path
from typing import Dict, List, Optional, Any, Callable, Union, Protocol
from threading import Lock
import psutil
import weakref

# üìä –†–∞—Å—à–∏—Ä–µ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ —Ç–∏–ø–æ–≤ —Å–æ–±—ã—Ç–∏–π
class EventType(Enum):
    """–¢–∏–ø—ã —Å–æ–±—ã—Ç–∏–π —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π –Ω—É–º–µ—Ä–∞—Ü–∏–µ–π"""
    # –°–∏—Å—Ç–µ–º–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è
    SYSTEM_START = auto()
    SYSTEM_SHUTDOWN = auto()
    HEALTH_CHECK = auto()
    
    # –°–æ–±—ã—Ç–∏—è –∞–Ω–∞–ª–∏–∑–∞
    ANALYSIS_START = auto()
    ANALYSIS_COMPLETE = auto()
    ANALYSIS_ERROR = auto()
    
    # –°–æ–±—ã—Ç–∏—è —Ñ–∞–π–ª–æ–≤
    FILE_SCAN_START = auto()
    FILE_SCAN_COMPLETE = auto()
    FILE_ANALYSIS_START = auto()
    FILE_ANALYSIS_COMPLETE = auto()
    
    # AI —Å–æ–±—ã—Ç–∏—è
    AI_REQUEST_START = auto()
    AI_REQUEST_COMPLETE = auto()
    AI_REQUEST_ERROR = auto()
    
    # –ú–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    PERFORMANCE_SAMPLE = auto()
    MEMORY_WARNING = auto()
    CPU_WARNING = auto()

class LogLevel(Enum):
    """–£—Ä–æ–≤–Ω–∏ –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
    MINIMAL = "minimal"      # –¢–æ–ª—å–∫–æ –∫—Ä–∏—Ç–∏—á–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è
    STANDARD = "standard"    # –°—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—ã–µ –æ–ø–µ—Ä–∞—Ü–∏–∏
    DETAILED = "detailed"    # –î–µ—Ç–∞–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è
    VERBOSE = "verbose"      # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏—è
    DEBUG = "debug"          # –û—Ç–ª–∞–¥–æ—á–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è

@dataclass
class MonitoringConfig:
    """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å–∏—Å—Ç–µ–º—ã –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"""
    log_level: LogLevel = LogLevel.STANDARD
    max_events_in_memory: int = 1000
    event_batch_size: int = 50
    metrics_retention_hours: int = 24
    performance_sample_interval: float = 30.0
    auto_cleanup_enabled: bool = True
    export_format: str = "json"  # json, csv, prometheus
    log_file_path: Optional[str] = None
    enable_console_output: bool = True
    memory_warning_threshold: float = 85.0
    cpu_warning_threshold: float = 80.0

@dataclass
class PerformanceMetrics:
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
    timestamp: datetime
    cpu_percent: float
    memory_percent: float
    memory_used_mb: float
    disk_usage_percent: float
    active_connections: int
    response_time_ms: Optional[float] = None
    
    def to_dict(self) -> Dict[str, Any]:
        """–°–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –ø–∞–º—è—Ç–∏"""
        return {
            'ts': self.timestamp.timestamp(),  # –ö–æ–º–ø–∞–∫—Ç–Ω—ã–π timestamp
            'cpu': round(self.cpu_percent, 2),
            'mem': round(self.memory_percent, 2),
            'mem_mb': round(self.memory_used_mb, 2),
            'disk': round(self.disk_usage_percent, 2),
            'conn': self.active_connections,
            'rt': round(self.response_time_ms, 2) if self.response_time_ms else None
        }

@dataclass
class MonitoringEvent:
    """–õ–µ–≥–∫–æ–≤–µ—Å–Ω–æ–µ —Å–æ–±—ã—Ç–∏–µ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"""
    event_id: str
    event_type: EventType
    timestamp: datetime
    level: LogLevel = LogLevel.STANDARD
    project_path: Optional[str] = None
    file_path: Optional[str] = None
    duration_ms: Optional[float] = None
    error_message: Optional[str] = None
    metadata: Dict[str, Any] = field(default_factory=dict)
    session_id: Optional[str] = None
    
    def should_log(self, configured_level: LogLevel) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª—è–µ—Ç, –Ω—É–∂–Ω–æ –ª–∏ –ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å —Å–æ–±—ã—Ç–∏–µ –Ω–∞ –∑–∞–¥–∞–Ω–Ω–æ–º —É—Ä–æ–≤–Ω–µ"""
        level_hierarchy = {
            LogLevel.MINIMAL: 0,
            LogLevel.STANDARD: 1, 
            LogLevel.DETAILED: 2,
            LogLevel.VERBOSE: 3,
            LogLevel.DEBUG: 4
        }
        return level_hierarchy[self.level] <= level_hierarchy[configured_level]
    
    def to_compact_dict(self) -> Dict[str, Any]:
        """–ö–æ–º–ø–∞–∫—Ç–Ω–∞—è —Å–µ—Ä–∏–∞–ª–∏–∑–∞—Ü–∏—è –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏"""
        data = {
            'id': self.event_id,
            'type': self.event_type.name,
            'ts': self.timestamp.timestamp(),
        }
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –Ω–µ-None –ø–æ–ª—è
        if self.project_path:
            data['project'] = self.project_path
        if self.file_path:
            data['file'] = self.file_path
        if self.duration_ms:
            data['duration'] = round(self.duration_ms, 2)
        if self.error_message:
            data['error'] = self.error_message
        if self.metadata:
            data['meta'] = self.metadata
        if self.session_id:
            data['session'] = self.session_id
            
        return data

# üè≠ –ê–±—Å—Ç—Ä–∞–∫—Ü–∏–∏ –¥–ª—è —Ä–∞—Å—à–∏—Ä—è–µ–º–æ—Å—Ç–∏

class EventExporter(Protocol):
    """–ü—Ä–æ—Ç–æ–∫–æ–ª –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞ —Å–æ–±—ã—Ç–∏–π"""
    
    def export_events(self, events: List[MonitoringEvent]) -> bool:
        """–≠–∫—Å–ø–æ—Ä—Ç —Å–ø–∏—Å–∫–∞ —Å–æ–±—ã—Ç–∏–π"""
        ...
    
    def export_metrics(self, metrics: List[PerformanceMetrics]) -> bool:
        """–≠–∫—Å–ø–æ—Ä—Ç –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        ...

class EventFormatter(ABC):
    """–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è —Ñ–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏—è —Å–æ–±—ã—Ç–∏–π"""
    
    @abstractmethod
    def format_event(self, event: MonitoringEvent) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–¥–Ω–æ–≥–æ —Å–æ–±—ã—Ç–∏—è"""
        pass
    
    @abstractmethod
    def format_batch(self, events: List[MonitoringEvent]) -> str:
        """–§–æ—Ä–º–∞—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–∞–∫–µ—Ç–∞ —Å–æ–±—ã—Ç–∏–π"""
        pass

class JSONFormatter(EventFormatter):
    """JSON —Ñ–æ—Ä–º–∞—Ç—Ç–µ—Ä –¥–ª—è —Å–æ–±—ã—Ç–∏–π"""
    
    def format_event(self, event: MonitoringEvent) -> str:
        return json.dumps(event.to_compact_dict(), ensure_ascii=False)
    
    def format_batch(self, events: List[MonitoringEvent]) -> str:
        return json.dumps([e.to_compact_dict() for e in events], ensure_ascii=False)

class FileExporter:
    """–≠–∫—Å–ø–æ—Ä—Ç —Å–æ–±—ã—Ç–∏–π –≤ —Ñ–∞–π–ª —Å —Ä–æ—Ç–∞—Ü–∏–µ–π"""
    
    def __init__(self, log_file_path: str, max_file_size_mb: int = 100):
        self.log_file_path = Path(log_file_path)
        self.max_file_size_bytes = max_file_size_mb * 1024 * 1024
        self.formatter = JSONFormatter()
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –µ—Å–ª–∏ –Ω–µ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
        self.log_file_path.parent.mkdir(parents=True, exist_ok=True)
    
    def export_events(self, events: List[MonitoringEvent]) -> bool:
        """–≠–∫—Å–ø–æ—Ä—Ç —Å–æ–±—ã—Ç–∏–π —Å –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–π —Ä–æ—Ç–∞—Ü–∏–µ–π —Ñ–∞–π–ª–æ–≤"""
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–º–µ—Ä —Ñ–∞–π–ª–∞ –∏ –≤—ã–ø–æ–ª–Ω—è–µ–º —Ä–æ—Ç–∞—Ü–∏—é –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏
            if self.log_file_path.exists() and self.log_file_path.stat().st_size > self.max_file_size_bytes:
                self._rotate_log_file()
            
            # –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Å–æ–±—ã—Ç–∏—è
            with open(self.log_file_path, 'a', encoding='utf-8') as f:
                for event in events:
                    f.write(f"{self.formatter.format_event(event)}\n")
            
            return True
        except Exception as e:
            logging.error(f"Failed to export events to file: {e}")
            return False
    
    def _rotate_log_file(self):
        """–†–æ—Ç–∞—Ü–∏—è –ª–æ–≥ —Ñ–∞–π–ª–∞"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        rotated_name = f"{self.log_file_path.stem}_{timestamp}.log"
        rotated_path = self.log_file_path.parent / rotated_name
        self.log_file_path.rename(rotated_path)

class OptimizedMonitoringSystem:
    """
    –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞ —Å —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ–º –ø–∞–º—è—Ç—å—é.
    
    –ö–ª—é—á–µ–≤—ã–µ –æ—Å–æ–±–µ–Ω–Ω–æ—Å—Ç–∏:
    - –ë–∞—Ç—á–∏–Ω–≥ —Å–æ–±—ã—Ç–∏–π –¥–ª—è —Å–Ω–∏–∂–µ–Ω–∏—è –Ω–∞–≥—Ä—É–∑–∫–∏ –Ω–∞ I/O
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    - –ö–æ–Ω—Ñ–∏–≥—É—Ä–∏—Ä—É–µ–º—ã–µ —É—Ä–æ–≤–Ω–∏ –¥–µ—Ç–∞–ª–∏–∑–∞—Ü–∏–∏
    - –õ–µ–Ω–∏–≤–∞—è –∑–∞–≥—Ä—É–∑–∫–∞ –º–µ—Ç—Ä–∏–∫
    - –°–ª–∞–±—ã–µ —Å—Å—ã–ª–∫–∏ –¥–ª—è –ø—Ä–µ–¥–æ—Ç–≤—Ä–∞—â–µ–Ω–∏—è —É—Ç–µ—á–µ–∫ –ø–∞–º—è—Ç–∏
    """
    
    def __init__(self, config: MonitoringConfig):
        self.config = config
        self._events_buffer: deque = deque(maxlen=config.max_events_in_memory)
        self._metrics_buffer: deque = deque(maxlen=config.max_events_in_memory // 10)
        self._session_stats: Dict[str, Dict] = {}
        self._active_operations: Dict[str, float] = {}
        self._buffer_lock = Lock()
        self._last_cleanup = time.time()
        self._event_counter = 0
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —ç–∫—Å–ø–æ—Ä—Ç–µ—Ä–æ–≤
        self._exporters: List[EventExporter] = []
        if config.log_file_path:
            self._exporters.append(FileExporter(config.log_file_path))
        
        # –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        self._setup_logging()
        
        # –ó–∞–ø—É—Å–∫ —Ñ–æ–Ω–æ–≤–æ–≥–æ –∑–∞–¥–∞–Ω–∏—è –¥–ª—è —Å–±–æ—Ä–∞ –º–µ—Ç—Ä–∏–∫
        self._metrics_task = None
        if config.performance_sample_interval > 0:
            self._start_metrics_collection()
    
    def _setup_logging(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–∏—Å—Ç–µ–º—ã –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è"""
        self.logger = logging.getLogger("optimized_monitoring")
        self.logger.setLevel(logging.INFO)
        
        if not self.logger.handlers and self.config.enable_console_output:
            handler = logging.StreamHandler()
            formatter = logging.Formatter(
                '%(asctime)s | MONITOR | %(levelname)s | %(message)s',
                datefmt='%H:%M:%S'
            )
            handler.setFormatter(formatter)
            self.logger.addHandler(handler)
    
    def _start_metrics_collection(self):
        """–ó–∞–ø—É—Å–∫ —Ñ–æ–Ω–æ–≤–æ–≥–æ —Å–±–æ—Ä–∞ –º–µ—Ç—Ä–∏–∫"""
        async def metrics_collector():
            while True:
                try:
                    await asyncio.sleep(self.config.performance_sample_interval)
                    await self._collect_performance_metrics()
                except Exception as e:
                    self.logger.error(f"Error in metrics collection: {e}")
        
        self._metrics_task = asyncio.create_task(metrics_collector())
    
    async def _collect_performance_metrics(self):
        """–°–±–æ—Ä –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏"""
        try:
            cpu_percent = psutil.cpu_percent(interval=None)
            memory = psutil.virtual_memory()
            disk = psutil.disk_usage('/')
            
            metrics = PerformanceMetrics(
                timestamp=datetime.now(timezone.utc),
                cpu_percent=cpu_percent,
                memory_percent=memory.percent,
                memory_used_mb=memory.used / (1024 * 1024),
                disk_usage_percent=disk.percent,
                active_connections=len(psutil.net_connections())
            )
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Ä–æ–≥–æ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
            if cpu_percent > self.config.cpu_warning_threshold:
                await self.log_event(MonitoringEvent(
                    event_id=self.generate_event_id(),
                    event_type=EventType.CPU_WARNING,
                    timestamp=metrics.timestamp,
                    level=LogLevel.STANDARD,
                    metadata={'cpu_percent': cpu_percent}
                ))
            
            if memory.percent > self.config.memory_warning_threshold:
                await self.log_event(MonitoringEvent(
                    event_id=self.generate_event_id(),
                    event_type=EventType.MEMORY_WARNING,
                    timestamp=metrics.timestamp,
                    level=LogLevel.STANDARD,
                    metadata={'memory_percent': memory.percent}
                ))
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
            with self._buffer_lock:
                self._metrics_buffer.append(metrics)
            
            # –ü–µ—Ä–∏–æ–¥–∏—á–µ—Å–∫–∞—è –æ—á–∏—Å—Ç–∫–∞
            if self.config.auto_cleanup_enabled:
                await self._cleanup_old_data()
                
        except Exception as e:
            self.logger.error(f"Error collecting performance metrics: {e}")
    
    def generate_event_id(self) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–º–ø–∞–∫—Ç–Ω–æ–≥–æ ID —Å–æ–±—ã—Ç–∏—è"""
        self._event_counter += 1
        return f"evt_{int(time.time())}{self._event_counter:04d}"
    
    async def log_event(self, event: MonitoringEvent):
        """–ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å–æ–±—ã—Ç–∏—è —Å –±–∞—Ç—á–∏–Ω–≥–æ–º"""
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Ä–æ–≤–µ–Ω—å –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
        if not event.should_log(self.config.log_level):
            return
        
        with self._buffer_lock:
            self._events_buffer.append(event)
            
            # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –±–∞—Ç—á –ø—Ä–∏ –¥–æ—Å—Ç–∏–∂–µ–Ω–∏–∏ –ª–∏–º–∏—Ç–∞
            if len(self._events_buffer) >= self.config.event_batch_size:
                await self._flush_events_batch()
    
    async def _flush_events_batch(self):
        """–û—Ç–ø—Ä–∞–≤–∫–∞ –±–∞—Ç—á–∞ —Å–æ–±—ã—Ç–∏–π —ç–∫—Å–ø–æ—Ä—Ç–µ—Ä–∞–º"""
        if not self._events_buffer:
            return
        
        # –ö–æ–ø–∏—Ä—É–µ–º —Å–æ–±—ã—Ç–∏—è –¥–ª—è —ç–∫—Å–ø–æ—Ä—Ç–∞
        events_to_export = list(self._events_buffer)
        self._events_buffer.clear()
        
        # –ê—Å–∏–Ω—Ö—Ä–æ–Ω–Ω—ã–π —ç–∫—Å–ø–æ—Ä—Ç
        for exporter in self._exporters:
            try:
                exporter.export_events(events_to_export)
            except Exception as e:
                self.logger.error(f"Error exporting events: {e}")
    
    @asynccontextmanager
    async def track_operation(self, 
                            operation_type: EventType,
                            level: LogLevel = LogLevel.STANDARD,
                            **kwargs):
        """–û—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ —Å –∏–∑–º–µ—Ä–µ–Ω–∏–µ–º –≤—Ä–µ–º–µ–Ω–∏"""
        
        event_id = self.generate_event_id()
        start_time = time.time()
        
        # –°–æ–±—ã—Ç–∏–µ –Ω–∞—á–∞–ª–∞
        start_event = MonitoringEvent(
            event_id=f"{event_id}_start",
            event_type=operation_type,
            timestamp=datetime.now(timezone.utc),
            level=level,
            **kwargs
        )
        await self.log_event(start_event)
        
        error_occurred = None
        try:
            yield event_id
        except Exception as e:
            error_occurred = e
            # –°–æ–±—ã—Ç–∏–µ –æ—à–∏–±–∫–∏
            error_event = MonitoringEvent(
                event_id=f"{event_id}_error",
                event_type=EventType.ANALYSIS_ERROR,
                timestamp=datetime.now(timezone.utc),
                level=LogLevel.STANDARD,
                error_message=str(e),
                **kwargs
            )
            await self.log_event(error_event)
            raise
        finally:
            # –°–æ–±—ã—Ç–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è
            duration_ms = (time.time() - start_time) * 1000
            complete_event = MonitoringEvent(
                event_id=f"{event_id}_complete",
                event_type=EventType.ANALYSIS_COMPLETE,
                timestamp=datetime.now(timezone.utc),
                level=level,
                duration_ms=duration_ms,
                metadata={'success': error_occurred is None},
                **kwargs
            )
            await self.log_event(complete_event)
    
    async def _cleanup_old_data(self):
        """–û—á–∏—Å—Ç–∫–∞ —É—Å—Ç–∞—Ä–µ–≤—à–∏—Ö –¥–∞–Ω–Ω—ã—Ö"""
        current_time = time.time()
        
        # –û—á–∏—â–∞–µ–º —Ç–æ–ª—å–∫–æ —Ä–∞–∑ –≤ —á–∞—Å
        if current_time - self._last_cleanup < 3600:
            return
        
        cutoff_time = datetime.now(timezone.utc) - timedelta(hours=self.config.metrics_retention_hours)
        
        with self._buffer_lock:
            # –û—á–∏—â–∞–µ–º —Å—Ç–∞—Ä—ã–µ –º–µ—Ç—Ä–∏–∫–∏
            while (self._metrics_buffer and 
                   self._metrics_buffer[0].timestamp < cutoff_time):
                self._metrics_buffer.popleft()
        
        self._last_cleanup = current_time
        self.logger.info(f"Cleanup completed. Metrics retained: {len(self._metrics_buffer)}")
    
    def get_analytics_summary(self, session_id: Optional[str] = None) -> Dict[str, Any]:
        """–ë—ã—Å—Ç—Ä–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –∞–Ω–∞–ª–∏—Ç–∏—á–µ—Å–∫–æ–π —Å–≤–æ–¥–∫–∏"""
        with self._buffer_lock:
            total_events = len(self._events_buffer)
            total_metrics = len(self._metrics_buffer)
        
        # –ü–æ—Å–ª–µ–¥–Ω–∏–µ –º–µ—Ç—Ä–∏–∫–∏
        latest_metrics = None
        if self._metrics_buffer:
            latest_metrics = self._metrics_buffer[-1].to_dict()
        
        return {
            'events_in_buffer': total_events,
            'metrics_in_buffer': total_metrics,
            'latest_metrics': latest_metrics,
            'config': {
                'log_level': self.config.log_level.value,
                'max_events': self.config.max_events_in_memory,
                'retention_hours': self.config.metrics_retention_hours
            },
            'system_info': {
                'active_exporters': len(self._exporters),
                'metrics_collection_active': self._metrics_task is not None and not self._metrics_task.done()
            }
        }
    
    async def shutdown(self):
        """–ö–æ—Ä—Ä–µ–∫—Ç–Ω–æ–µ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–∞–±–æ—Ç—ã —Å–∏—Å—Ç–µ–º—ã"""
        self.logger.info("Shutting down monitoring system...")
        
        # –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Å–±–æ—Ä –º–µ—Ç—Ä–∏–∫
        if self._metrics_task:
            self._metrics_task.cancel()
            try:
                await self._metrics_task
            except asyncio.CancelledError:
                pass
        
        # –°–±—Ä–∞—Å—ã–≤–∞–µ–º –æ—Å—Ç–∞–≤—à–∏–µ—Å—è —Å–æ–±—ã—Ç–∏—è
        await self._flush_events_batch()
        
        self.logger.info("Monitoring system shutdown complete")

# üéõÔ∏è –§–∞–±—Ä–∏–∫–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –Ω–∞—Å—Ç—Ä–æ–µ–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
class MonitoringFactory:
    """–§–∞–±—Ä–∏–∫–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –ø—Ä–µ–¥—É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω—ã—Ö –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–π –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"""
    
    @staticmethod
    def create_development_monitoring(log_file: Optional[str] = None) -> OptimizedMonitoringSystem:
        """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏"""
        config = MonitoringConfig(
            log_level=LogLevel.VERBOSE,
            max_events_in_memory=500,
            event_batch_size=25,
            performance_sample_interval=60.0,
            log_file_path=log_file,
            enable_console_output=True
        )
        return OptimizedMonitoringSystem(config)
    
    @staticmethod
    def create_production_monitoring(log_file: str) -> OptimizedMonitoringSystem:
        """–ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –¥–ª—è –ø—Ä–æ–¥–∞–∫—à–µ–Ω–∞"""
        config = MonitoringConfig(
            log_level=LogLevel.STANDARD,
            max_events_in_memory=2000,
            event_batch_size=100,
            performance_sample_interval=30.0,
            log_file_path=log_file,
            enable_console_output=False,
            auto_cleanup_enabled=True
        )
        return OptimizedMonitoringSystem(config)
    
    @staticmethod
    def create_minimal_monitoring() -> OptimizedMonitoringSystem:
        """–ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è"""
        config = MonitoringConfig(
            log_level=LogLevel.MINIMAL,
            max_events_in_memory=100,
            event_batch_size=50,
            performance_sample_interval=0,  # –û—Ç–∫–ª—é—á–∞–µ–º –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π —Å–±–æ—Ä
            enable_console_output=False
        )
        return OptimizedMonitoringSystem(config)

# üåü –ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º –∫–æ–¥–æ–º
def create_monitoring_system(environment: str = "development") -> OptimizedMonitoringSystem:
    """
    –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è —Å–∏—Å—Ç–µ–º—ã –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞.
    
    Args:
        environment: development, production, minimal
    
    Returns:
        –ù–∞—Å—Ç—Ä–æ–µ–Ω–Ω–∞—è —Å–∏—Å—Ç–µ–º–∞ –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞
    """
    if environment == "production":
        return MonitoringFactory.create_production_monitoring("logs/mcp_analyzer.log")
    elif environment == "minimal":
        return MonitoringFactory.create_minimal_monitoring()
    else:
        return MonitoringFactory.create_development_monitoring("logs/mcp_analyzer_dev.log")
